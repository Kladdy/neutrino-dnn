run1:
    In this run, 5 different models are tested with varying levels of learning rates for the Adam optimizer
    The different values for the learning are are 
        run1.1: 0.001 
        run1.2: 0.0005
        run1.3: 0.0001  
        run1.4: 0.00005  
        run1.5: 0.00001   

    With the following python scripts:
        python T13.py run1.1 0.001
        python T13.py run1.2 0.0005
        python T13.py run1.3 0.0001
        python T13.py run1.4 0.00005
        python T13.py run1.5 0.00001

run2: 
    The goal of this run is to clean up and automate as much of the code base as possible