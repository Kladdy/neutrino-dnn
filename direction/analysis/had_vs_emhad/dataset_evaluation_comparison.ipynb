{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mPlotting resolution as function of neutrino properties for run_EMHAD_vs_HAD...\u001b[0m\n",
      "ITS SIXTYEIGHT!\n",
      "Calulating with statistic SIXTYEIGHT...\n",
      "loading file 38\n",
      "finished loading file 38 in 7.557665824890137s\n",
      "loading file 39\n",
      "finished loading file 39 in 7.411792278289795s\n",
      "loading file 40\n",
      "finished loading file 40 in 7.380567789077759s\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plots/model.run_EMHAD_vs_HAD.h5_predicted.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21871/1196229824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;31m# Get angle difference data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mangle_difference_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pred_angle_diff_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplots_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0msigma_68_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_{68}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neutrino-dnn/direction/analysis/had_vs_emhad/toolbox.py\u001b[0m in \u001b[0;36mget_pred_angle_diff_data\u001b[0;34m(run_name, dataset, plots_dir)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_pred_angle_diff_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplots_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mprediction_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{plots_dir}/model.{run_name}.h5_predicted.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"br\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mnu_direction_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plots/model.run_EMHAD_vs_HAD.h5_predicted.pkl'"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# (MODEL, DATASET)\n",
    "comparisons = [\n",
    "    (\"EMHAD\", \"HAD\"),\n",
    "    (\"HAD\", \"EMHAD\")\n",
    "]\n",
    "\n",
    "for model_tag, dataset_tag in comparisons:\n",
    "    project_name = \"nu-dir-reco\"\n",
    "    # run_version = \"runF1\"\n",
    "    dataset_name = \"SouthPole\"\n",
    "\n",
    "    # Dataset setup\n",
    "    # Call Dataset(dataset_name, em, noise) with\n",
    "    #     dataset_name:\n",
    "    #         ALVAREZ (only had + noise) / ARZ\n",
    "    #     em:\n",
    "    #         True / False (default)\n",
    "    #     noise:\n",
    "    #         True (default) / False\n",
    "    dataset_name = \"ARZ\"\n",
    "    dataset_em = False if dataset_tag == \"HAD\" else True\n",
    "    dataset_noise = True\n",
    "\n",
    "    dataset = datasets.Dataset(dataset_name, dataset_em, dataset_noise)\n",
    "\n",
    "    test_file_ids = dataset.test_file_ids\n",
    "    datapath = dataset.datapath\n",
    "    data_filename = dataset.data_filename\n",
    "    label_filename = dataset.label_filename\n",
    "    n_files = dataset.n_files\n",
    "    n_files_val = dataset.n_files_val\n",
    "\n",
    "    # Directories\n",
    "    plots_dir = \"plots\"\n",
    "    saved_model_dir = \"saved_models_HAD\" if dataset_tag == \"HAD\" else \"saved_models_EMHAD\"\n",
    "\n",
    "    # Imports\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from toolbox import get_pred_angle_diff_data, load_file_all_properties\n",
    "    import sys\n",
    "    import argparse\n",
    "    import os\n",
    "    import time\n",
    "    import pickle\n",
    "    from NuRadioReco.utilities import units\n",
    "    from scipy import stats\n",
    "    from radiotools import stats as rtSTATS\n",
    "    from termcolor import colored\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from itertools import product, combinations\n",
    "    from radiotools import plthelpers as php\n",
    "    from tensorflow import keras\n",
    "    from radiotools import helper as hp\n",
    "    # -------\n",
    "\n",
    "    def plot_same(x_data, ax1_data_y, ax2_data_y):\n",
    "        print(f\"Plotting {file_name}...\")\n",
    "\n",
    "        fig_same, ax1 = plt.subplots()\n",
    "\n",
    "        ax1.set_xlabel(x_label)\n",
    "        ax1.set_ylabel(ax1_y_label)\n",
    "\n",
    "        # Set ax1 to high order to make it be in front so label is in front, and datapoints\n",
    "        #ax1.set_zorder(1)\n",
    "\n",
    "        if file_name == \"nu_energy\":\n",
    "            ax1.set_xscale('log')\n",
    "\n",
    "        # Remove last peices of data as their bins are weird for some azimuth\n",
    "        if file_name == \"nu_energy\" or file_name == \"nu_azimuth\" or file_name == \"nu_SNR\":\n",
    "            x_data = x_data[0:-1]\n",
    "            ax1_data_y = ax1_data_y[0:-1]\n",
    "            ax2_data_y = ax2_data_y[0:-1]\n",
    "\n",
    "        # Remove any bins with zero events for nu_zenith\n",
    "        if file_name == \"nu_zenith\":\n",
    "            ind_count_not_0 = ax2_data_y != 0\n",
    "            x_data = x_data[ind_count_not_0]\n",
    "            ax1_data_y = ax1_data_y[ind_count_not_0]\n",
    "            ax2_data_y = ax2_data_y[ind_count_not_0]\n",
    "\n",
    "        lns1 = ax1.plot(x_data, ax1_data_y, \"*\", color=ax1_color, label = ax1_y_label)\n",
    "\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "        ax2.set_ylabel(ax2_y_label) # we already handled the x-label with ax1\n",
    "        lns2 = ax2.plot(x_data, ax2_data_y, \"^\", color=ax2_color, label = ax2_y_label)\n",
    "\n",
    "        # Set axis limits so they are same on all plots\n",
    "        if file_name == \"nu_energy\":\n",
    "            ax1.set_ylim(0, 13.5)\n",
    "            ax2.set_ylim(0, 27000)\n",
    "        elif file_name == \"nu_SNR\":\n",
    "            ax2.set_yscale('log')\n",
    "            ax1.set_ylim(0, 22.5)\n",
    "            ax2.set_ylim(9, 2e5)\n",
    "        elif file_name == \"nu_zenith\":\n",
    "            ax2.set_yscale('log')\n",
    "            ax1.set_ylim(0, 40)\n",
    "            ax2.set_ylim(1.1, 300000)\n",
    "        elif file_name == \"nu_azimuth\":\n",
    "            ax1.set_ylim(0, 8)\n",
    "            ax2.set_ylim(0, 13500)\n",
    "\n",
    "        plt.title(plot_title)\n",
    "\n",
    "        # added these three lines\n",
    "        lns = lns1+lns2\n",
    "        labs = [l.get_label() for l in lns]\n",
    "        ax1.legend(lns, labs, loc=legend_loc)\n",
    "\n",
    "        fig_same.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "        #plt.subplots_adjust(top=0.88)\n",
    "        if eps:\n",
    "            fig_same.savefig(f\"{plot_dir}/sigma68_{file_name}_same_{run_name}_statistic_{statistic_string}.eps\", format=\"eps\", bbox_inches='tight')\n",
    "        else:\n",
    "            fig_same.savefig(f\"{plot_dir}/sigma68_{file_name}_same_{run_name}_statistic_{statistic_string}.png\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "    # Parse arguments\n",
    "    # parser = argparse.ArgumentParser(description='Plot performance data')\n",
    "    # parser.add_argument('--eps', dest='eps', action='store_true', help=\"flag to image as .eps instead of .png\")\n",
    "    # parser.add_argument('--median', dest='median', action='store_true', help=\"flag to do median instead of mean\")\n",
    "    # parser.add_argument('--sixtyeight', dest='sixtyeight', action='store_true', help=\"flag to do 68 percent interval\")\n",
    "    # parser.set_defaults(eps=False)\n",
    "    # parser.set_defaults(median=False)\n",
    "    # parser.set_defaults(sixtyeight=False)\n",
    "\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    eps = False\n",
    "    median = False\n",
    "    sixtyeight = True\n",
    "\n",
    "    # Save the run name\n",
    "    run_name = f\"run_{model_tag}_vs_{dataset_tag}\"\n",
    "    if run_name == \"run_HAD_vs_EMHAD\":\n",
    "        emission_model = \"ARZ2020 (had. model, had. + EM dataset)\"\n",
    "    elif run_name == \"run_EMHAD_vs_HAD\":\n",
    "        emission_model = \"ARZ2020 (had. + EM model, had. dataset)\"\n",
    "    else: raise Exception()\n",
    "\n",
    "    print(colored(f\"Plotting resolution as function of neutrino properties for {run_name}...\", \"yellow\"))\n",
    "\n",
    "    # Define 68 % interval statistic function\n",
    "    def calculate_percentage_interval(angle_difference_data):\n",
    "        percentage=0.68\n",
    "        N = angle_difference_data.size\n",
    "        weights = np.ones(N)\n",
    "\n",
    "        angle = rtSTATS.quantile_1d(angle_difference_data, weights, percentage)\n",
    "\n",
    "        return angle\n",
    "\n",
    "\n",
    "    # See which statistic to calculate...\n",
    "    # if median:\n",
    "    #     print(\"ITS MEDIAN!\")\n",
    "    #     statistic = \"median\"\n",
    "    #     statistic_string = \"Median\"\n",
    "    # else:\n",
    "    #     statistic = \"mean\"\n",
    "    #     statistic_string = \"Mean\"\n",
    "\n",
    "    if sixtyeight:\n",
    "        print(\"ITS SIXTYEIGHT!\")\n",
    "        statistic = calculate_percentage_interval\n",
    "        statistic_string = \"SIXTYEIGHT\"\n",
    "\n",
    "    print(f\"Calulating with statistic {statistic_string}...\")\n",
    "\n",
    "\n",
    "    # Make sure plots folder exists\n",
    "    if not os.path.exists(plots_dir):\n",
    "        os.makedirs(plots_dir)\n",
    "\n",
    "    plot_dir = f\"{plots_dir}/{run_name}_plots\"\n",
    "    plot_dir_old = f\"{plots_dir}/{run_name}_plots/old\"\n",
    "\n",
    "    # Make sure folder inside plot_folder exists for the plots\n",
    "    if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "\n",
    "    # Make sure folder inside plot_folder exists for the plots\n",
    "    if not os.path.exists(plot_dir_old):\n",
    "        os.makedirs(plot_dir_old)\n",
    "\n",
    "    # Make sure predicted file exists, otherwise run evaluator\n",
    "    prediction_file = \"saved_models_HAD/model.runF2.1.h5_predicted copy.pkl\" if model_tag == \"HAD\" else \"saved_models_EMHAD/model.runF3.1.h5_predicted copy.pkl\"\n",
    "    if not os.path.isfile(prediction_file):\n",
    "        print(\"Prediction file does not exist\", prediction_file)\n",
    "        raise Exception(\"Prediction does not exist\")\n",
    "        # os.system(f\"python evaluator.py\")\n",
    "\n",
    "    # Load test file data\n",
    "        # Load first file\n",
    "    data, nu_direction, nu_zenith, nu_azimuth, nu_energy, nu_flavor, shower_energy = load_file_all_properties(test_file_ids[0], dataset, plots_dir)\n",
    "\n",
    "        # Then load rest of files\n",
    "    if len(test_file_ids) > 1:\n",
    "        for test_file_id in test_file_ids:\n",
    "            if test_file_id != test_file_ids[0]:\n",
    "                data_tmp, nu_direction_tmp, nu_zenith_tmp, nu_azimuth_tmp, nu_energy_tmp, nu_flavor_tmp, shower_energy_tmp = load_file_all_properties(test_file_id, dataset, plots_dir)\n",
    "\n",
    "                data = np.concatenate((data, data_tmp))\n",
    "                nu_direction = np.concatenate((nu_direction, nu_direction_tmp))\n",
    "                nu_zenith = np.concatenate((nu_zenith, nu_zenith_tmp))\n",
    "                nu_azimuth = np.concatenate((nu_azimuth, nu_azimuth_tmp))\n",
    "                nu_energy = np.concatenate((nu_energy, nu_energy_tmp))\n",
    "                nu_flavor = np.concatenate((nu_flavor, nu_flavor_tmp))\n",
    "                shower_energy = np.concatenate((shower_energy, shower_energy_tmp))\n",
    "\n",
    "\n",
    "    # Get angle difference data\n",
    "    angle_difference_data = get_pred_angle_diff_data(run_name, dataset, plots_dir, prediction_file)\n",
    "\n",
    "    sigma_68_string = \"_{68}\"\n",
    "\n",
    "    # --------- Energy plotting ---------\n",
    "    # Create figure\n",
    "    fig_energy = plt.figure()\n",
    "\n",
    "    # Calculate binned statistics\n",
    "    ax = fig_energy.add_subplot(1, 1, 1)\n",
    "    nu_energy_bins = np.logspace(np.log10(1e17),np.log10(10**19), 30)\n",
    "    nu_energy_bins_with_one_extra = np.append(np.logspace(np.log10(1e17),np.log10(10**19), 30), [1e20])\n",
    "    binned_resolution_nu_energy = stats.binned_statistic(nu_energy, angle_difference_data, bins = nu_energy_bins_with_one_extra, statistic=statistic)[0]\n",
    "\n",
    "    ax.plot(nu_energy_bins, binned_resolution_nu_energy, \"*\", color=\"darkorange\")\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_xlabel(r\"True $\\nu$ energy (eV)\")\n",
    "    ax.set_ylabel(r\"Mean $\\sigma_{68}$ in bin (°)\")\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "\n",
    "    # ax = fig_energy.add_subplot(1, 2, 2)\n",
    "    # ax.plot(nu_energy, angle_difference_data, 'o')\n",
    "    # ax.set_xscale('log')\n",
    "\n",
    "\n",
    "    plt.title(fr\"Mean value of $\\sigma{sigma_68_string}$ as a function of $\\nu$ energy for dataset {emission_model}\")\n",
    "    fig_energy.tight_layout()\n",
    "    fig_energy.savefig(f\"{plot_dir_old}/{statistic_string}_resolution_nu_energy_{run_name}.png\")\n",
    "    # ___________________________________\n",
    "\n",
    "    # --------- Energy count plotting ---------\n",
    "    # Create figure\n",
    "    fig_energy_count = plt.figure()\n",
    "\n",
    "    # Calculate binned statistics\n",
    "    ax = fig_energy_count.add_subplot(1, 1, 1)\n",
    "    binned_resolution_nu_energy_count = stats.binned_statistic(nu_energy, angle_difference_data, bins = nu_energy_bins_with_one_extra, statistic = \"count\")[0]\n",
    "\n",
    "    ax.plot(nu_energy_bins, binned_resolution_nu_energy_count, \"*\")\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_xlabel(r\"True $\\nu$ energy (eV)\")\n",
    "    ax.set_ylabel(\"Events\")\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    plt.title(fr\"Count of events inside $\\nu$ energy bins for dataset {emission_model}\")\n",
    "    fig_energy_count.tight_layout()\n",
    "    fig_energy_count.savefig(f\"{plot_dir_old}/{statistic_string}_resolution_nu_energy_count_{run_name}.png\")\n",
    "    # ___________________________________\n",
    "\n",
    "    # Energy resolution & count on same axis\n",
    "    # Constants:\n",
    "    ax1_color = 'tab:blue'\n",
    "    ax2_color = 'tab:orange'\n",
    "    x_label = r\"True $\\nu$ energy (eV)\"\n",
    "    ax1_y_label = fr\"$\\sigma{sigma_68_string}$ in bin (°)\"\n",
    "    ax2_y_label = \"Events\"\n",
    "\n",
    "    x_data = nu_energy_bins\n",
    "    ax1_data_y = binned_resolution_nu_energy\n",
    "    ax2_data_y = binned_resolution_nu_energy_count\n",
    "\n",
    "    file_name = \"nu_energy\"\n",
    "    plot_title_1 = fr\"Value of $\\sigma{sigma_68_string}$ as a function of $\\nu$ energy\"\n",
    "    plot_title_2 = fr\"count of events inside $\\nu$ energy bins for dataset {emission_model}\"\n",
    "    plot_title = plot_title_1 + \", and\\n\" + plot_title_2\n",
    "    legend_loc = \"upper center\"\n",
    "    # Constants END\n",
    "\n",
    "    plot_same(x_data, ax1_data_y, ax2_data_y)\n",
    "    # ______________________________________\n",
    "\n",
    "\n",
    "    # --------- Azimuth plotting ---------\n",
    "    # Create figure\n",
    "    fig_azimuth = plt.figure()\n",
    "\n",
    "    # Calculate binned statistics\n",
    "    ax = fig_azimuth.add_subplot(1, 1, 1)\n",
    "    nu_azimuth_bins = np.linspace(0,np.deg2rad(360), 30)\n",
    "    nu_azimuth_bins_with_one_extra = np.append(np.linspace(0,np.deg2rad(360), 30), 2*np.pi+1)\n",
    "    binned_resolution_nu_azimuth = stats.binned_statistic(nu_azimuth, angle_difference_data, bins = nu_azimuth_bins_with_one_extra, statistic=statistic)[0]\n",
    "\n",
    "    ax.plot(nu_azimuth_bins / units.deg, binned_resolution_nu_azimuth, \"o\")\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_xlabel(\"true neutrino direction azimuth angle (°)\")\n",
    "    ax.set_ylabel(\"angular resolution (°)\")\n",
    "\n",
    "\n",
    "    plt.title(f\"Mean resolution as a function of nu_azimuth for {run_name}\")\n",
    "    fig_azimuth.tight_layout()\n",
    "    fig_azimuth.savefig(f\"{plot_dir_old}/{statistic_string}_resolution_nu_azimuth_{run_name}.png\")\n",
    "    # ___________________________________\n",
    "\n",
    "    # --------- Azimuth count plotting ---------\n",
    "    # Create figure\n",
    "    fig_azimuth_count = plt.figure()\n",
    "\n",
    "    # Calculate binned statistics\n",
    "    ax = fig_azimuth_count.add_subplot(1, 1, 1)\n",
    "\n",
    "    binned_resolution_nu_azimuth_count = stats.binned_statistic(nu_azimuth, angle_difference_data, bins = nu_azimuth_bins_with_one_extra, statistic = \"count\")[0]\n",
    "\n",
    "    ax.plot(nu_azimuth_bins / units.deg, binned_resolution_nu_azimuth_count, \"o\")\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_xlabel(\"true neutrino direction azimuth angle (°)\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "\n",
    "\n",
    "    plt.title(f\"Count of events inside bins as a function of nu_azimuth for {run_name}\")\n",
    "    fig_azimuth_count.tight_layout()\n",
    "    fig_azimuth_count.savefig(f\"{plot_dir_old}/{statistic_string}_resolution_nu_azimuth_count_{run_name}.png\")\n",
    "    # ___________________________________\n",
    "\n",
    "    # Azimuth resolution & count on same axis\n",
    "    # Constants:\n",
    "    x_label = r\"True $\\nu$ azimuth angle (°)\"\n",
    "    ax1_y_label = fr\"$\\sigma{sigma_68_string}$ in bin (°)\"\n",
    "    ax2_y_label = \"Events\"\n",
    "\n",
    "    x_data = nu_azimuth_bins / units.deg\n",
    "    ax1_data_y = binned_resolution_nu_azimuth\n",
    "    ax2_data_y = binned_resolution_nu_azimuth_count\n",
    "\n",
    "    file_name = \"nu_azimuth\"\n",
    "    plot_title_1 = fr\"Value of $\\sigma{sigma_68_string}$ as a function of $\\nu$ azimuth angle\"\n",
    "    plot_title_2 = fr\"count of events inside $\\nu$ azimuth angle bins for dataset {emission_model}\"\n",
    "    plot_title = plot_title_1 + \", and\\n\" + plot_title_2\n",
    "    legend_loc = \"upper left\"\n",
    "    # Constants END\n",
    "\n",
    "    plot_same(x_data, ax1_data_y, ax2_data_y)\n",
    "    # ______________________________________\n",
    "\n",
    "\n",
    "\n",
    "    # --------- Zenith plotting ---------\n",
    "    # Create figure\n",
    "    fig_zenith = plt.figure()\n",
    "\n",
    "    # Calculate binned statistics\n",
    "    ax = fig_zenith.add_subplot(1, 1, 1)\n",
    "    nu_zenith_bins = np.linspace(0,np.pi, 30)\n",
    "    nu_zenith_bins_with_one_extra = np.append(np.linspace(0,np.pi, 30), np.pi+1)\n",
    "    binned_resolution_nu_zenith = stats.binned_statistic(nu_zenith, angle_difference_data, bins = nu_zenith_bins_with_one_extra, statistic=statistic)[0]\n",
    "\n",
    "    ax.plot(nu_zenith_bins / units.deg, binned_resolution_nu_zenith, \"o\")\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_xlabel(\"true neutrino direction zenith angle (°)\")\n",
    "    ax.set_ylabel(\"angular resolution (°)\")\n",
    "\n",
    "    plt.title(f\"Mean resolution as a function of nu_zenith for {run_name}\")\n",
    "    fig_zenith.tight_layout()\n",
    "    fig_zenith.savefig(f\"{plot_dir_old}/{statistic_string}_resolution_nu_zenith_{run_name}.png\")\n",
    "    # ___________________________________\n",
    "\n",
    "    # --------- Zenith count plotting ---------\n",
    "    # Create figure\n",
    "    fig_zenith_count = plt.figure()\n",
    "\n",
    "    # Calculate binned statistics\n",
    "    ax = fig_zenith_count.add_subplot(1, 1, 1)\n",
    "    binned_resolution_nu_zenith_count = stats.binned_statistic(nu_zenith, angle_difference_data, bins = nu_zenith_bins_with_one_extra, statistic = \"count\")[0]\n",
    "\n",
    "    ax.plot(nu_zenith_bins / units.deg, binned_resolution_nu_zenith_count, \"o\")\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_xlabel(\"true neutrino direction zenith angle (°)\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "\n",
    "    plt.title(f\"Count of events inside bins as a function of nu_zenith for {run_name}\")\n",
    "    fig_zenith_count.tight_layout()\n",
    "    fig_zenith_count.savefig(f\"{plot_dir_old}/{statistic_string}_resolution_nu_zenith_count_{run_name}.png\")\n",
    "    # ___________________________________\n",
    "\n",
    "    # Zenith resolution & count on same axis\n",
    "    # Constants:\n",
    "    x_label = r\"True $\\nu$ zenith angle (°)\"\n",
    "    ax1_y_label = fr\"$\\sigma{sigma_68_string}$ in bin (°)\"\n",
    "    ax2_y_label = \"Events\"\n",
    "\n",
    "    x_data = nu_zenith_bins / units.deg\n",
    "    ax1_data_y = binned_resolution_nu_zenith\n",
    "    ax2_data_y = binned_resolution_nu_zenith_count\n",
    "\n",
    "    file_name = \"nu_zenith\"\n",
    "    plot_title_1 = fr\"Value of $\\sigma{sigma_68_string}$ as a function of $\\nu$ zenith angle\"\n",
    "    plot_title_2 = fr\"count of events inside $\\nu$ zenith angle bins for dataset {emission_model}\"\n",
    "    plot_title = plot_title_1 + \", and\\n\" + plot_title_2\n",
    "    legend_loc = \"upper left\"\n",
    "    # Constants END\n",
    "\n",
    "    plot_same(x_data, ax1_data_y, ax2_data_y)\n",
    "    # ______________________________________\n",
    "\n",
    "\n",
    "\n",
    "    # --------- SNR plotting ---------\n",
    "    max_LPDA = np.max(np.max(np.abs(data[:, 0:4, :]), axis=2), axis=1)\n",
    "\n",
    "    # print(max_LPDA[:, 0])\n",
    "    # index_max_LPDA_big = max_LPDA[:, 0] * 10 > 300\n",
    "    # print(max_LPDA.index(index_max_LPDA_big[0]))\n",
    "\n",
    "\n",
    "    # print(\"data.shape:\", data.shape)\n",
    "    # #print(\"data:\", data)\n",
    "\n",
    "    # print(\"data[:, :, 0:4].shape\", data[:, 0:4, :].shape)\n",
    "    # #print(\"data[:, :, 0:4]\", data[:, 0:4, :])\n",
    "\n",
    "    # print(\"np.abs(data[:, :, 0:4]).shape\", np.abs(data[:, 0:4, :]).shape)\n",
    "    # #print(\"np.abs(data[:, :, 0:4])\", np.abs(data[:, 0:4, :]))\n",
    "\n",
    "    # print(\"np.max(np.abs(data[:, :, 0:4]), axis=1).shape:\", np.max(np.abs(data[:, 0:4, :]), axis=2).shape)\n",
    "    # #print(\"np.max(np.abs(data[:, :, 0:4]), axis=1):\", np.max(np.abs(data[:, 0:4, :]), axis=1))\n",
    "\n",
    "    # print(\"np.max(np.max(np.abs(data[:, :, 0:4]), axis=1), axis=1).shape:\", np.max(np.max(np.abs(data[:, 0:4, :]), axis=2), axis=1).shape)\n",
    "    # #print(\"np.max(np.max(np.abs(data[:, :, 0:4]), axis=1), axis=1):\", np.max(np.max(np.abs(data[:, 0:4, :]), axis=1), axis=1))\n",
    "\n",
    "    # Create figure\n",
    "    fig_SNR = plt.figure()\n",
    "\n",
    "    # Calculate binned statistics\n",
    "    ax = fig_SNR.add_subplot(1, 1, 1)\n",
    "\n",
    "    SNR_means = np.linspace(2, 10, 30)\n",
    "    SNR_bins = np.append(np.linspace(2, 10, 30), 10000)\n",
    "\n",
    "    #SNR_means = np.arange(0.5, 300.5, 1)\n",
    "    #SNR_bins = np.append(np.arange(0, 300, 1), [10000])\n",
    "\n",
    "    binned_resolution_SNR_mean = stats.binned_statistic(max_LPDA[:, 0] / 10., angle_difference_data, bins=SNR_bins, statistic=statistic)[0]\n",
    "\n",
    "    ax.plot(SNR_means, binned_resolution_SNR_mean, \"o\")\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_xlabel(\"SNR\")\n",
    "    ax.set_ylabel(\"angular resolution (°)\")\n",
    "\n",
    "    plt.title(f\"Mean resolution as a function of SNR for {run_name}\")\n",
    "    fig_SNR.tight_layout()\n",
    "    fig_SNR.savefig(f\"{plot_dir_old}/{statistic_string}_resolution_SNR_{run_name}.png\")\n",
    "    # ___________________________________\n",
    "\n",
    "    # --------- SNR count plotting ---------\n",
    "    # Create figure\n",
    "    fig_SNR_count = plt.figure()\n",
    "\n",
    "    # Calculate binned statistics\n",
    "    ax = fig_SNR_count.add_subplot(1, 1, 1)\n",
    "\n",
    "    binned_resolution_SNR_mean_count = stats.binned_statistic(max_LPDA[:, 0] / 10., angle_difference_data, bins=SNR_bins, statistic = \"count\")[0]\n",
    "\n",
    "    ax.plot(SNR_means, binned_resolution_SNR_mean_count, \"o\")\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_xlabel(\"SNR\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "\n",
    "    plt.title(f\"Count of events inside bins as a function of SNR for {run_name}\")\n",
    "    fig_SNR_count.tight_layout()\n",
    "    fig_SNR_count.savefig(f\"{plot_dir_old}/{statistic_string}_resolution_SNR_count_{run_name}.png\")\n",
    "    # ___________________________________\n",
    "\n",
    "\n",
    "    # SNR resolution & count on same axis\n",
    "    # Constants:\n",
    "    x_label = r\"Event SNR\"\n",
    "    ax1_y_label = fr\"$\\sigma{sigma_68_string}$ in bin (°)\"\n",
    "    ax2_y_label = \"Events\"\n",
    "\n",
    "    x_data = SNR_means\n",
    "    ax1_data_y = binned_resolution_SNR_mean\n",
    "    ax2_data_y = binned_resolution_SNR_mean_count\n",
    "\n",
    "    file_name = \"nu_SNR\"\n",
    "    plot_title_1 = fr\"Value of $\\sigma{sigma_68_string}$ as a function of event SNR\"\n",
    "    plot_title_2 = fr\"count of events inside SNR bins for dataset {emission_model}\"\n",
    "    plot_title = plot_title_1 + \", and\\n\" + plot_title_2\n",
    "    legend_loc = \"upper right\"\n",
    "    # Constants END\n",
    "\n",
    "    plot_same(x_data, ax1_data_y, ax2_data_y)\n",
    "    # ______________________________________\n",
    "\n",
    "\n",
    "    # Save plotting data for plotting all at once\n",
    "    with open(f'{plots_dir}/plotdata_{statistic_string}_{run_name}.npy', 'wb') as f:\n",
    "        np.save(f, nu_energy_bins)\n",
    "        np.save(f, binned_resolution_nu_energy)\n",
    "        np.save(f, binned_resolution_nu_energy_count)\n",
    "\n",
    "        np.save(f, nu_azimuth_bins / units.deg)\n",
    "        np.save(f, binned_resolution_nu_azimuth)\n",
    "        np.save(f, binned_resolution_nu_azimuth_count)\n",
    "\n",
    "        np.save(f, nu_zenith_bins / units.deg)\n",
    "        np.save(f, binned_resolution_nu_zenith)\n",
    "        np.save(f, binned_resolution_nu_zenith_count)\n",
    "\n",
    "        np.save(f, SNR_means)\n",
    "        np.save(f, binned_resolution_SNR_mean)\n",
    "        np.save(f, binned_resolution_SNR_mean_count)\n",
    "\n",
    "    print(colored(f\"Plotting angular resolution depending on properties for {run_name}!\", \"green\", attrs=[\"bold\"]))\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f00e6b041018f9c5003ba88af84c1401696fe75920157f0e0f441a09854937f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
